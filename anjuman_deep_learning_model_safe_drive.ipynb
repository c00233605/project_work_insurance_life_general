{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following figure is a typical Deep learning model [1] The Convolution part does the feature extraction from the input and the part with dense layers does the classification part. In our case we have extracted features. So, our model only consists of dense layers.\n",
    "<img src=\"cnn.jpg\" width=\"400\" height=\"50\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing panda and numpy library to load data from the xlsx file into a data frame and extract features out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next loading data into a data frame `df` and then displaying first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EngineHP</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>Years_Experience</th>\n",
       "      <th>annual_claims</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Vehical_type</th>\n",
       "      <th>Miles_driven_annually</th>\n",
       "      <th>size_of_family</th>\n",
       "      <th>Age_bucket</th>\n",
       "      <th>EngineHP_bucket</th>\n",
       "      <th>Years_Experience_bucket</th>\n",
       "      <th>Miles_driven_annually_bucket</th>\n",
       "      <th>credit_history_bucket</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>522</td>\n",
       "      <td>656</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Car</td>\n",
       "      <td>14749.0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;18</td>\n",
       "      <td>&gt;350</td>\n",
       "      <td>&lt;3</td>\n",
       "      <td>&lt;15k</td>\n",
       "      <td>Fair</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>691</td>\n",
       "      <td>704</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Car</td>\n",
       "      <td>15389.0</td>\n",
       "      <td>6</td>\n",
       "      <td>28-34</td>\n",
       "      <td>&gt;350</td>\n",
       "      <td>15-30</td>\n",
       "      <td>15k-25k</td>\n",
       "      <td>Good</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>133</td>\n",
       "      <td>691</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Van</td>\n",
       "      <td>9956.0</td>\n",
       "      <td>3</td>\n",
       "      <td>&gt;40</td>\n",
       "      <td>90-160</td>\n",
       "      <td>15-30</td>\n",
       "      <td>&lt;15k</td>\n",
       "      <td>Good</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>146</td>\n",
       "      <td>720</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Van</td>\n",
       "      <td>77323.0</td>\n",
       "      <td>3</td>\n",
       "      <td>18-27</td>\n",
       "      <td>90-160</td>\n",
       "      <td>9-14'</td>\n",
       "      <td>&gt;25k</td>\n",
       "      <td>Good</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>128</td>\n",
       "      <td>771</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>Married</td>\n",
       "      <td>Van</td>\n",
       "      <td>14183.0</td>\n",
       "      <td>4</td>\n",
       "      <td>&gt;40</td>\n",
       "      <td>90-160</td>\n",
       "      <td>&gt;30</td>\n",
       "      <td>&lt;15k</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  target Gender  EngineHP  credit_history  Years_Experience  \\\n",
       "0   1       1      F       522             656                 1   \n",
       "1   2       1      F       691             704                16   \n",
       "2   3       1      M       133             691                15   \n",
       "3   4       1      M       146             720                 9   \n",
       "4   5       1      M       128             771                33   \n",
       "\n",
       "   annual_claims Marital_Status Vehical_type  Miles_driven_annually  \\\n",
       "0              0        Married          Car                14749.0   \n",
       "1              0        Married          Car                15389.0   \n",
       "2              0        Married          Van                 9956.0   \n",
       "3              0        Married          Van                77323.0   \n",
       "4              1        Married          Van                14183.0   \n",
       "\n",
       "   size_of_family Age_bucket EngineHP_bucket Years_Experience_bucket  \\\n",
       "0               5        <18            >350                      <3   \n",
       "1               6      28-34            >350                   15-30   \n",
       "2               3        >40          90-160                   15-30   \n",
       "3               3      18-27          90-160                   9-14'   \n",
       "4               4        >40          90-160                     >30   \n",
       "\n",
       "  Miles_driven_annually_bucket credit_history_bucket State  \n",
       "0                         <15k                  Fair    IL  \n",
       "1                      15k-25k                  Good    NJ  \n",
       "2                         <15k                  Good    CT  \n",
       "3                         >25k                  Good    CT  \n",
       "4                         <15k             Very Good    WY  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_excel(\"IT_3.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need `ID` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only selecting the columns which are going to use as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['Vehical_type',  'EngineHP_bucket', 'Years_Experience_bucket', 'Miles_driven_annually_bucket', 'credit_history_bucket', 'State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are doing one hot encoding by using `pandas` function `get_dummies`, that means every value in a categorical type column will be turned into a column and the value will be replace by 1 and 0. \n",
    "\n",
    "| ID | car | millage |\n",
    "| --- | --- | --- |\n",
    "| 1 | Mercedes | 2000 |\n",
    "| 2 | Mercedes | 50000 |\n",
    "| 3 | Honda | 3000 |\n",
    "| 4 | VW | 50 |\n",
    "\n",
    "The above table will be turn into as following table.\n",
    "\n",
    "| ID | car Mercedes | car Honda| car VW | millage |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 1 | 1 | 0 | 0 | 2000 |\n",
    "| 2 | 1 | 0 | 0 | 50000 |\n",
    "| 3 | 0 | 1 | 0 | 3000 |\n",
    "| 4 | 0 | 0 | 1 | 50 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.get_dummies(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = features.to_numpy(copy = True)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `target` columns for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df[[\"target\"]]\n",
    "labels = labels.to_numpy(copy = True)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `scikit-learn` library and `train_test_split` function to divide our data for training the model and testing the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries for defining deep learning model, layers and training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a model with few dense and dropout layers. For dense layer the activation function is `relu` and the last layer it is `sigmoid`. The first layer is input layer with input dimension is equal to the number of feature value. We print out the model summary at the end of defining the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 100)               7200      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 70)                7070      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               7100      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 23,411\n",
      "Trainable params: 23,411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation=\"relu\", input_dim = len(features[0])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(70, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize the training process we use `adam` optimizer function, `binary_crossentropy` calculation for the loss calculation and then `accuracy` as a metrics. So, the model will try to adjust it weight and bias value to achieve higher possible accuracy with lower possible loss and in a optimized way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined model and also define the compilation techniques. Now we shall run the actual training with the training data. It is better to use a portion of data for the validation of the training process to see whether with the data we are having under fitting or over fitting problem. To store the logs and to generate the diagram to compare the loss and accuracy curve of training and validation during training process we first need to use `tensorboard` library. Then we shall use `fit` function to run the actual training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "log_dir='logs/{}'.format(time())\n",
    "tensorboard = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6264 - accuracy: 0.6894 - val_loss: 0.6174 - val_accuracy: 0.7019\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6105 - accuracy: 0.7074 - val_loss: 0.6119 - val_accuracy: 0.7019\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6077 - accuracy: 0.7077 - val_loss: 0.6104 - val_accuracy: 0.7019\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6021 - accuracy: 0.7120 - val_loss: 0.6108 - val_accuracy: 0.7019\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6058 - accuracy: 0.7075 - val_loss: 0.6098 - val_accuracy: 0.7019\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6024 - accuracy: 0.7086 - val_loss: 0.6095 - val_accuracy: 0.7019\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6085 - accuracy: 0.7020 - val_loss: 0.6093 - val_accuracy: 0.7019\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6009 - accuracy: 0.7103 - val_loss: 0.6103 - val_accuracy: 0.7019\n",
      "Epoch 9/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 0.7073 - val_loss: 0.6097 - val_accuracy: 0.7019\n",
      "Epoch 10/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5939 - accuracy: 0.7121 - val_loss: 0.6101 - val_accuracy: 0.7019\n",
      "Epoch 11/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5963 - accuracy: 0.7100 - val_loss: 0.6105 - val_accuracy: 0.7019\n",
      "Epoch 12/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5951 - accuracy: 0.7099 - val_loss: 0.6116 - val_accuracy: 0.7019\n",
      "Epoch 13/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5998 - accuracy: 0.7045 - val_loss: 0.6173 - val_accuracy: 0.7019\n",
      "Epoch 14/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5926 - accuracy: 0.7116 - val_loss: 0.6163 - val_accuracy: 0.7019\n",
      "Epoch 15/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5911 - accuracy: 0.7084 - val_loss: 0.6123 - val_accuracy: 0.7019\n",
      "Epoch 16/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5875 - accuracy: 0.7122 - val_loss: 0.6136 - val_accuracy: 0.7019\n",
      "Epoch 17/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5916 - accuracy: 0.7045 - val_loss: 0.6127 - val_accuracy: 0.7019\n",
      "Epoch 18/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5871 - accuracy: 0.7076 - val_loss: 0.6168 - val_accuracy: 0.7019\n",
      "Epoch 19/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5787 - accuracy: 0.7143 - val_loss: 0.6152 - val_accuracy: 0.7019\n",
      "Epoch 20/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5846 - accuracy: 0.7086 - val_loss: 0.6159 - val_accuracy: 0.7019\n",
      "Epoch 21/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.7063 - val_loss: 0.6162 - val_accuracy: 0.7019\n",
      "Epoch 22/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5826 - accuracy: 0.7081 - val_loss: 0.6208 - val_accuracy: 0.7019\n",
      "Epoch 23/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5783 - accuracy: 0.7134 - val_loss: 0.6169 - val_accuracy: 0.7019\n",
      "Epoch 24/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5727 - accuracy: 0.7148 - val_loss: 0.6196 - val_accuracy: 0.7019\n",
      "Epoch 25/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5795 - accuracy: 0.7063 - val_loss: 0.6208 - val_accuracy: 0.7019\n",
      "Epoch 26/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.7060 - val_loss: 0.6203 - val_accuracy: 0.7019\n",
      "Epoch 27/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5725 - accuracy: 0.7118 - val_loss: 0.6270 - val_accuracy: 0.7017\n",
      "Epoch 28/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5721 - accuracy: 0.7120 - val_loss: 0.6241 - val_accuracy: 0.7017\n",
      "Epoch 29/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.7094 - val_loss: 0.6347 - val_accuracy: 0.7022\n",
      "Epoch 30/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5735 - accuracy: 0.7080 - val_loss: 0.6407 - val_accuracy: 0.7015\n",
      "Epoch 31/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7122 - val_loss: 0.6375 - val_accuracy: 0.6980\n",
      "Epoch 32/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5621 - accuracy: 0.7152 - val_loss: 0.6304 - val_accuracy: 0.6982\n",
      "Epoch 33/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.7190 - val_loss: 0.6441 - val_accuracy: 0.6984\n",
      "Epoch 34/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5604 - accuracy: 0.7195 - val_loss: 0.6336 - val_accuracy: 0.6989\n",
      "Epoch 35/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7144 - val_loss: 0.6490 - val_accuracy: 0.6927\n",
      "Epoch 36/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5618 - accuracy: 0.7143 - val_loss: 0.6507 - val_accuracy: 0.6929\n",
      "Epoch 37/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5615 - accuracy: 0.7123 - val_loss: 0.6383 - val_accuracy: 0.6962\n",
      "Epoch 38/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5637 - accuracy: 0.7163 - val_loss: 0.6522 - val_accuracy: 0.6903\n",
      "Epoch 39/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5537 - accuracy: 0.7202 - val_loss: 0.6439 - val_accuracy: 0.6806\n",
      "Epoch 40/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5542 - accuracy: 0.7236 - val_loss: 0.6509 - val_accuracy: 0.6792\n",
      "Epoch 41/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.7193 - val_loss: 0.6578 - val_accuracy: 0.6808\n",
      "Epoch 42/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5587 - accuracy: 0.7171 - val_loss: 0.6423 - val_accuracy: 0.6836\n",
      "Epoch 43/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.7141 - val_loss: 0.6760 - val_accuracy: 0.6907\n",
      "Epoch 44/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7169 - val_loss: 0.6560 - val_accuracy: 0.6841\n",
      "Epoch 45/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5524 - accuracy: 0.7229 - val_loss: 0.6648 - val_accuracy: 0.6797\n",
      "Epoch 46/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.7204 - val_loss: 0.6639 - val_accuracy: 0.6863\n",
      "Epoch 47/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5573 - accuracy: 0.7175 - val_loss: 0.6664 - val_accuracy: 0.6863\n",
      "Epoch 48/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5519 - accuracy: 0.7227 - val_loss: 0.6646 - val_accuracy: 0.6728\n",
      "Epoch 49/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5548 - accuracy: 0.7209 - val_loss: 0.6773 - val_accuracy: 0.6790\n",
      "Epoch 50/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5508 - accuracy: 0.7237 - val_loss: 0.6603 - val_accuracy: 0.6821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2029300b820>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch_size means how many number will take for fit\n",
    "model.fit(train_features,train_labels,batch_size = 50, epochs= 50, validation_split =0.2, shuffle = True, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot loss and accuracy curve using the `tensorboard` to see whether there is under fitting or over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 8088 (pid 9924), started 0:00:59 ago. (Use '!kill 9924' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f26c0931b778f972\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f26c0931b778f972\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8088;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {log_dir} --host localhost --port 8088"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the trained model with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756/756 [==============================] - 1s 575us/step - loss: 0.6827 - accuracy: 0.6868\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(test_features,test_labels,batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing loss and accuracy value as a final evaluation of our model to predict the `target` column that gives the indication whether the insurance holder is going to make a claim or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loss: {}, accuracy: {}\".format(loss,accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "1. Daniel Weimer, Bernd Scholz-Reiter, Moshe Shpitalni,\n",
    "Design of deep convolutional neural network architectures for automated feature extraction in industrial inspection,\n",
    "CIRP Annals,\n",
    "Volume 65, Issue 1,\n",
    "2016,\n",
    "Pages 417-420,\n",
    "ISSN 0007-8506,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
